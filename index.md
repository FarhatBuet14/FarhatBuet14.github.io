---
layout: hero-home
title: ""
cover_image: /assets/img/cover.jpg
profile_image: /assets/img/avatar.jpg
hero_title: |
  Postdoctoral Scholar (AI Research & Engineering)
  University of South Florida (USF)
  Tampa, FL-33620, USA
  _________________________________

hero_subtitle: |
  • Computer Vision
  • Trustworthy/Explainable AI
  • Edge-to-Cloud AI Systems
  • Public Health AI
  
  <span class="hl-bg">I’m actively exploring Applied Scientist / Machine Learning Engineer / Computer Vision Engineer / Edge AI roles</span>

  <div class="hero-social">
    <a class="hero-social__btn" href="https://www.linkedin.com/in/farhat-binte-azam-ph-d-4415a9144/" target="_blank" rel="noopener" aria-label="LinkedIn">
      <i class="fa-brands fa-linkedin-in"></i>
    </a>
    <a class="hero-social__btn" href="https://github.com/FarhatBuet14" target="_blank" rel="noopener" aria-label="GitHub">
      <i class="fa-brands fa-github"></i>
    </a>
    <a class="hero-social__btn" href="https://scholar.google.com/citations?user=LLvagBQAAAAJ&hl=en" target="_blank" rel="noopener" aria-label="Google Scholar">
      <i class="fa-solid fa-graduation-cap"></i>
    </a>
  </div>


---

I build **deployable computer-vision systems** for **real-world sensing and decision support**, with a focus on **trustworthy/explainable AI** and **end-to-end deployment** (edge capture → cloud analytics → stakeholder-facing tools). My work sits at the intersection of **machine learning**, **public health**, and **systems engineering**, where models are evaluated not only by accuracy but by **robustness, interpretability, and operational usability**.

---

## Current focus areas
- <span class="c-blue"><strong>MosquitoAI:</strong></span> AI-powered mosquito surveillance from heterogeneous imagery and field-deployed traps  
- <span class="c-green"><strong>Dense-object localization:</strong></span> robust detection under occlusion, clutter, and domain shift  
- <span class="c-yellow"><strong>Trustworthy AI:</strong></span> explainability, uncertainty-aware monitoring, and human-in-the-loop  

---

## Highlights
- <span class="c-red"><strong>10+ publications</strong></span> in interdisciplinary venues spanning AI + biomedicine + entomology  
- <span class="c-red"><strong>1 U.S. patent </strong></span> on computer-vision–based biological inference  
- Field-facing collaborations with <span class="c-red"><strong>public-health partners</strong></span> to translate models into real surveillance workflows  

---

## Technical strengths
**Modeling**
- CNNs + Transformers for vision, detection, and segmentation  
- Handling imbalance: sampling strategies, loss design, threshold selection, and metric-driven tuning  
- Interpretable ML: ROI-based analysis, saliency methods

**Engineering**
- Python ML stacks (training, evaluation, visualization, packaging)  
- Dataset + experiment management, reproducibility, and reporting  
- System integration patterns for edge devices and cloud inference

<!-- --- -->

<!-- ## Collaboration
I work comfortably across **AI/ML**, **software**, and **domain science** teams—translating needs into measurable objectives, iterating quickly, and keeping outputs usable for decision-makers. -->

<!-- ---

## Opportunities
<span class="hl-bg">I’m actively exploring Applied Scientist / Machine Learning Engineer / Computer Vision Engineer / Edge AI roles</span>


If you think there’s a fit, please reach out via the **Contact** page. -->


<style>
.hero-social{
  display:flex;
  gap:10px;
  margin-top:10px;
  justify-content:flex-start;  /* left */
  align-items:center;
}
.hero-social__btn{
  width:34px;
  height:34px;
  border-radius:10px;
  display:inline-flex;
  align-items:center;
  justify-content:center;
  text-decoration:none;
  border:1px solid rgba(255,255,255,0.18);
  background:rgba(0,0,0,0.22);
  color:rgba(255,255,255,0.95);
  transition:transform .12s ease, border-color .12s ease;
}
.hero-social__btn:hover{
  transform:translateY(-1px);
  border-color:rgba(255,255,255,0.35);
}
.hero-social__btn i{
  font-size:16px;
  line-height:1;
}
</style>
